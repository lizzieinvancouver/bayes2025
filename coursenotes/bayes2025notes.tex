\documentclass[11pt]{article}
\usepackage[top=1.00in, bottom=1.0in, left=1in, right=1in]{geometry}
\renewcommand{\baselinestretch}{1.1}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{todonotes}


\def\labelitemi{--}
\parindent=0pt

\begin{document}
\bibliographystyle{/Users/Lizzie/Documents/EndnoteRelated/Bibtex/styles/besjournals}
\renewcommand{\refname}{\CHead{}}

\tableofcontents

% To do moved to git issue: https://github.com/temporalecologylab/bayes2025/issues/1

\newpage
\section{Class 1}  % I threw out my paper notes from today as there was not much on then; next time i teach make up board notes of eqns etc.!

FIX: Next time ... 
\begin{itemize}
\item Draw out dots on $y=\alpha + \beta (x)$ versus with error (off line)
\item Point out today or tomorrow that memorizing $ypred=\alpha + \beta (x)$ and $y_i \sim normal(ypred, \sigma^2)$ will make it easier to learn out distributions that focusing on $y_i=\alpha + \beta (x) + \epsilon$ and $\epsilon \sim normal(0, \sigma^2)$ 
\end{itemize}

\subsection{Structure of today}
\begin{itemize}
\item Few minutes for urgent course content questions ... 
\item Review what is Bayesian (briefly) and the workflow I will teach for it
\item Focus on simulating data from a linear regression
\item END: course content, grading etc..
\end{itemize}
Okay! You all should have received my email about the course, which means\\ {\bf you're here because ... }
\begin{itemize}
\item Excited to learn Bayesian inference and modeling!
\item Excited to work together in pairs or teams during class (even if you're auditing)
\item Know enough R to code actively in class 
\item Have a laptop and note-taking devices
\end{itemize}
If you're {\bf not sure} about any of these, stay here and come talk with me after. 

\subsection{Round-robin of quick intros}
Who is in the class...

\subsection{Who I am and course aims ...}

{\bf Who am I?} Quick review of how I learned Bayesian and how it is all I basically used now. Like many died in the wool Bayesians I believe this makes me: 
\begin{itemize}
\item Happier, free from p-values
\item Think harder about the science
\item Have a WAY better sense of how the models I use work and how well they work on data similar to my own. 
\item More suspicious of a lot of stats
\end{itemize}

\subsection{Before I dive in ... reminder: don't panic} % Don't panic: How to get the most out of a stats class
No one gets everything in a stats class the first time, but you need to keep listening and not zone out.

\subsection{What I want you to get out of this class} 
\begin{itemize}
\item The basics of what Bayesian is and how to implement
\item The importance of a workflow and understand one I use and recommend
\item Give some example of what they'll be able to do at the end (will vary by student)
\item Get some of your burning questions answered ... {\bf Feel free to ask questions/interrupt!}
\item You probably will not come out of this class ready to analyze cut-point ordinal models for your community ecology data, but you'll have the workflow skills to start to think about to approach such a problem. 
\end{itemize}

\subsection{What is Bayesian? Pros and cons}
It's a way of getting estimates from a model based on the likelihood from data and your prior beliefs.\\
It's a way of fitting and inferring from models that is extremely flexible and relies on prior knowledge. (That's basically all you need to know for today.)\\

\todo[inline]{Ask the students to list out pros and cons. Make sure they hit the below.}

Pros
\begin{itemize}
\item Very flexible!
\item Optimally handles uncertainty
\item Intuitive
\item No assumptions! No iid, nothing to memorize!
\item Stop worrying about what your p-value is or contorting yourself to accurately define a CI
\item Get mechanistic insights!
\item Have a better sense of your parameter estimates
\end{itemize}

Cons
\begin{itemize}
\item No assumptions, you must check your own model and know what you're doing ... 
\item Computationally heavy
\end{itemize}

\subsubsection{Types of Bayesians}
There are {\bf many} types of Bayesians:
\begin{itemize}
\item Andy Royle Bayesians with specific beliefs about how you fit mark-recapture models
\item People obsessed with DAGs
\item Facultative Bayesians
\item Andrew Gelman Bayesians (BDA)
\end{itemize}

{\bf I will teach you my style of Bayesian ...} which is pretty close to a Gelman Bayesian with other ideas (Betancourt etc.) thrown in. 

{\bf This does not matter! Except when you go out into the world} and meet the other Bayesians.

\subsection{What is Bayesian? A workflow}

\begin{enumerate}
\item Come up with your model
\item Simulate data from your model to check it
\item Prior predictive checks
\item Run your model on empirical data
\item Retrodictive checks (aka PPCs)
\end{enumerate}

\emph{This class will focus on most of this workflow!} \\Except step 1 and we won't dwell on step 2 (prior checks).

\subsection{Simulate from a linear model: Part 1}

{\bf We're going to use something that works with linear regression for our model, so continuous $x$ and continuous $y$}
\todo[inline]{Get class to come up with an example and DRAW it out on a graph} Options: Plant growth in response to soil nutrient concentration, biometric scaling etc. 

\todo[inline]{Ask students equation for a line.}
Write out various notations and differentiate {\bf {\Large parameters}} from {\bf \Large data}} (ideally, skip the error here)

\emph{Okay, I want to simulate data from this equation, what do I do?}

In this section be sure to ...
\begin{itemize}
\item Slope versus intercept
\item Come up with parameter numbers to write on board
\item Mention \verb|rnorm|
\item Get the ERROR onto the equation if you have not already
\item mention $n$
\item What is an effect size? 
\end{itemize}

\todo[inline]{Students should pair up and work on doing this with the following rules ...} 
\begin{itemize}
\item You must BOTH end up with the code you come up with.
\item Simulate, plot and then try to figure out a way to tell if you have done it right... 
\item You alert me when you're done, stuck or have a question ... [If they are done, they should check their work using \verb|lm|, then try to simulate a LOGISTIC regression.]
\end{itemize}

\todo[inline]{Note to self: Give the class a 10 minute break by 3pm!} 

\subsection{Simulate from a linear model: Part 2}

Come together and review how they did. Live code with them the course example using \verb|lm| and \verb|stan_glm| to check work. 

\todo[inline]{Discuss: How might this be valuable?} 
And be sure to discuss why this is critical in Bayesian approaches ...\\
NO assumptions; you must CHECK and UNDERSTAND your model.

\subsection{Simulate from a linear model: Add interactions}

Review this if time allows .... 
\begin{itemize}
\item Intercept only model
\item Adding an interaction to a model ... 
\end{itemize}

Go through the math on the board, introduce dummy variables and then set them to try to simulate a model with an interaction and see if they can return the parameters. \\
Or, we get to this tomorrow more likely ... 

\subsection{Review of course (by 4:20pm)}
\begin{itemize}
\item 3 weeks, 6 classes, we'll get to hierarchical modeling
\item ... but I am not sure when! I reserve the right to move things around (small chance I will start hierarchical modeling next week). 
\item Grading is participation and homework
\item There are TWO homework (end of each of the first 2 weeks). Please do them! Even if you are auditing.
\item No project, you must use a provided dataset
\item Course managed on GitHub; you can submit homework on GitHub or Canvas. 
\item GitHub has wiki with resources ... Review (if time allows)
\item We will use rstanarm, which is a version of Stan -- make sure you have it running before the next class. 
\item Remind me to give you a BREAK in the middle of class
\item Questions?
\end{itemize}

%%%%%%%%%%%%
%%%%%%%%%%%%
\newpage
\section{Class 2} 
\emph(May want to have start of class 2 (MCMC) prepped!)

Stuff to have prepped for this class .... Part 1 ({\bf finished at 4:15pm first time, but depends on questions!})
\begin{itemize}
\item TWO or three articles to show ... (Flynn \& Wolkovich, OSPREE bb ms and Morales-Castilla)
\item Code that goes with some of them % git/projects/treegarden/budexperiments/analyses/FakeBudburst_Generate.R and pmm repo for example
\item \url{https://www.countbayesie.com/blog/2015/2/18/hans-solo-and-bayesian-priors} % What is the posterior?
\item The html from \url{https://github.com/lizzieinvancouver/bayesianflowsexample} for prior predictive checks (but I could find/make better example)
\item priorpost code (misspecify model)
\end{itemize}

Stuff to have prepped for this class .... Part 2 (MCMC) 
\begin{itemize}
\item The html from \url{https://github.com/lizzieinvancouver/bayesianflowsexample}
\item \url{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=banana}
\end{itemize}

Stuff to have prepped for this class .... HOMEWORK review at the end!

{\bf Review the workflow!} Write it up  and point to where we are \\
...maybe tell them -- yes! 
You will spend more of your life fitting models to not your empirical data if you properly use the Bayesian workflow.\\
Give TWO-THREE examples of this in papers (post code for the test data later). \\ % Flynn & Wolkovich, Ettinger 2020, Morales-Castilla (nice, because I can show the pmm repo)
\begin{itemize}
\item Flynn \& Wolkovich: I stopped using 2-way interactions
\item Ettinger et al. 2020: No interactions given uneven data and following the workflow we realized this was not good, main effects average over interactions
\item Morales-Castilla et al. 2024: We ask different questions, no need for big models, but still writing important papers (could mention decsens)
\end{itemize}
Maybe touch on -- I have ended up with simpler models. \\

{\bf Review equations from yesterday ...}
Be sure to encourage them to move towards the one without $normal(0, \sigma)$  use $normal(\mu, \sigma)$

\subsection{What is Bayesian: Posterior}
Go over it. Maybe on the chalkboard ...  

Use the webpage eventually to come up with an example
\href{https://www.countbayesie.com/blog/2015/2/18/hans-solo-and-bayesian-priors}{Give my Star Wars example.}

\todo[inline]{Discuss in pairs: Another example (if time allows)} 

Other examples: Complete separation.... Dolph's Iraq war example (which is not great).

\subsection{What is Bayesian: Prior}

\todo[inline]{Note to LIZZIE: Think about order below} 

{\bf Two take-homes I want them to get ...} This is repeated later in this document ....
\begin{enumerate}
\item It's not that hard to come up with potentially informative priors that you should feel good about. You have them most often, you just need to get better at thinking about them.
\item In many models, data can overwhelm your priors. 
\end{enumerate}

Types of priors (informative, non-informative (often $uniform(0,1)$ meaning everything EQUALLY possible, weakly informative)... in 2024 I wrote them out and crossed off non-informative, I taught weakly as 3X and draw out on board what happens if prior constrains posterior and then you go up 3X. Be sure to WRITE out the math of the prior here (what I mean by 3X) and DRAW it. 

\todo[inline]{Discuss in pairs: An example of a prior you would set on a parameter related to your system (or just a fun example). (Only time allows)} 
Round robin of how would you set a prior for your data ... (set model first).

Could give my example of coming up with priors for synchrony (days per decade known of 3-5 days per decade, also give extremes we know are too big -- 100 days per year or decade is clearly NOT happening, for example -- and that y axis limits me some here).  Should also draw and WRITE out example here. Could even open class with this as a STORY?

\subsection{How much do priors matter?}
It depends ..... ask the class what they think it depends on.

\todo[inline]{... ask the class what they think it depends on.} 

EXAMPLE: Show code where likelihood overwhelms prior. Can go through Stan briefly if time allows and introduce MCMC. 

EXAMPLE: Show prior predictive check from \url{https://github.com/lizzieinvancouver/bayesianflowsexample/blob/main/example.html} 

Why we will not do prior checks ... \\ Because they are annoying in rstanarm, brms etc. They are easier in raw Stan code. 

{\bf Two take-homes: Make sure you say this!} From above...
\begin{enumerate}
\item It's not that hard to come up with potentially informative priors that you should feel good about. You have them most often, you just need to get better at thinking about them.
\item In many models, data can overwhelm your priors. 
\end{enumerate}


\subsection{MAYBE: Simulate another example ... and fit it in rstanarm} 
\subsection{OR: Start on MCMC...} Moved my notes from here to next class 

% \subsection{Cover interactions! If you have not already ...}
% Go through the math on the board, introduce dummy variables and then set them to try to simulate a model with an interaction and see if they can return the parameters. 


\subsection{Review the homework assignment!}
\begin{itemize}
\item Go over the tasks (homework on board)
\item Review the datasets briefly (mention hierarchical)
\item How to submit
\begin{itemize}
\item GitHub -- do you all want write access?
\item Canvas (but I prefer GitHub)
\end{itemize}
\item What to do if you get stuck ... ask classmates for help, use Piazza, move onto next step. 
\item A note on using ChatGPT
\end{itemize}

%%%%%%%%%%%%
%%%%%%%%%%%%
\newpage
\section{Class 3} 

Stuff to have prepped for this class .... (MCMC) 
\begin{itemize}
\item HOMEWORK!
\item Gelman blog posts on interactions ... 
% \item The html from \url{https://github.com/lizzieinvancouver/bayesianflowsexample} % Not sure why I wanted this, using diagnostics day which is easier. 
\item \url{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=banana}
\item \verb|ncp_needed.png|
\item \verb|diagnostiscsday.R| and make sure it's running well
\end{itemize}

{\bf Review the homework!} 
\todo[inline]{Have the class count off by 4-6 or such to end up in groups of 3-4 and then compare their homework}  During this I should get a tally on which datasets people picked.

In small groups cover:
\begin{itemize}
\item Decide which parameters fit best or worst and discuss WHY?
\item What common issues did they have in coding?
\end{itemize}

As a whole group, cover the homework to discuss ... 
\begin{itemize}
\item What was hard? 
\item What parameters fit better or worse? 
\item Get to what they learned about interactions ... (16X) -- review what you need to calculate power:
\begin{itemize}
\item Sample size
\item error ($\sigma_y$)
\item effect size (`sledgehammer' experiments are used for a reason)
\end{itemize}
\item I will post my version of the homework ...
\end{itemize}

\subsection{What is MCMC? And why do we need it ...}

{\Large Announce to class:} You do not need to understand MCMC (or HMC) super well to do Bayesian, but you need to understand the diagnostics and having some sense of the algorithm can help with that (but don't panic if you don't get the algorithm, focus on the diagnostics and keep learning). \\

To get a posterior in Bayesian, we don't compute it, we instead (generally) get samples from it using an algorithm. \\
Sampling for Bayesian models almost always have 3 ingredients:

\begin{enumerate}
\item Monte Carlo -- process to generate random draws (\verb|rnorm| or $\normal(\theta, \sigma)$)
\item Markov chain -- Monte Carlo with correlated steps $\normal(\theta_{n-1}, \sigma)$
\item Algorithm -- e.g., Metropolis Hastings (FYI, you can use this for things other than getting samples from a posterior)
\end{enumerate}

{\bf How many dimensions is a posterior?} As many dimensions as the number of parameters you have. \\

ON THE BOARD: give an example for linear regression (alpha, beta, sigma) and walk through for Metropolis Hastings. \\
Steps are: 

\begin{enumerate}
\item Start somewhere (initial conditions)
\item Use the Monte Carlo to get a random place to jump ($\theta_{new}$)
\item Now evaluate your posterior here relative to where you were
\item If your jump is better, accept and jump there! ($\theta_{new+1}$)
\item If your jump is no better, then you compare the ratio to a random draw from a uniform (0,1) distribution; if the ratio is higher than this value you jump anyway. (Acceptance probability.)
\item If the ratio is lower than this value you {\bf don't jump} -- your proposal is {\bf rejected}; draw new random jump (step 2) and repeat
% \item If your jump is better, you flip a coin to decide whether to stay 
\end{enumerate}
\todo[inline]{Ask the class: Why do you sometimes accept lower ratios?} To help your chain search fully ... Each random draw means you can go down the hill. Otherwise your chain gets into crevices and does not search fully, {\bf SEARCHING fully the challenge.} Give the roomba vacuum example. 

{\bf Problems: (1) The start of the chain is not good.}

{\bf Problems: (2) The steps are correlated.}

{\bf Solutions? One is multiple chains!} 

Others ... 
\begin{itemize}
\item Drop the start of the chain
\item Thin the samples
\item Another is to run chains a LONG time (Gibbs)
\item Get a better algorithm
\end{itemize}

NEXT: Discuss proposal issue and mention Gibbs (Gibbs uses conjugate priors to make more efficient proposals).\\ % Gibbs is named after some guy called Gibbs

THEN: mention Stan and what it does conceptually. See page 247 of \emph{Statistical Rethinking}: HMC runs a particle simulation so it can move quickly through flat posterior space and slower through complex space. 

Then spend a while looking at: \url{https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=banana}

(Maybe mention `hill-climbing' -- which is what this is in some ways.)

MENTION: Warmup and total iterations needed ... 

{\bf How many dimensions is a posterior?} As many dimensions as the number of parameters you have. \\
So it's a complex space to search! \\

Mention GIBBS and how it works (long runs, search for chain hangups) versus Stan (divergences).

{\bf Divergent transitions:} ``A divergence arises when the simulated Hamiltonian trajectory departs from the true trajectory as measured by departure of the Hamiltonian value from its initial value. When this divergence is too high, the simulation has gone off the rails and cannot be trusted." In other words, something is wrong in your model.  % https://mc-stan.org/docs/2_19/reference-manual/divergent-transitions

A few notes on divergences:
\begin{itemize}
\item You should not report estimates in a paper if you have divergent transitions! You must get rid of them ....
\item Technically, any are bad and you should consider re-parameterizing your model to make your posterior a friendlier shape to search
\item Some times smaller steps get rid of them (adapt delta command)
\item Usually you can get rid of a small number (meh, under 30) -- if you have hundreds for 4000 steps then something is DEEPLY wrong. 
\end{itemize}

\subsection{MCMC diagnostics}

The three basic ones!
\begin{enumerate}
\item Rhat -- compare variance with a chain to variance across chains
\item $n_{effective}$ -- aim for 10\% of your total iterations 
\item msce -- Markov Chain SE -- I never use this as I have never seen it be uniquely helpful
\end{enumerate}

And ... Divergences -- pairs plots -- LOOK up \verb|ncp_needed.png| And discuss.

Go through ShinyStan using \verb|diagnostiscsday.R| 



%%%%%%%%%%%%
%%%%%%%%%%%%
\newpage
\section{Class 4} 
\todo[inline]{This lecture did not go below as planned ... this is how it went:}

\begin{enumerate}
\item Asked the class lead-in question (this worked)
\item Drew some plots (this worked}
\item Immediately ended up at no pooling/partial pooling/complete pooling so should plan on that and have better no pooling notation ($y_{[sp]i}$ and $\sigma_{[sp]}$)
\end{enumerate}

Stuff to have prepped for this class .... 
\begin{itemize}
\item Homework assignment! For the end
\item OPSREE paper showing plot of random effects
\item Code that simulates hierarchical data -- see \verb|hierarchicalday.R| and the \verb|figureskating| folder
\item Plot showing partial pooling (shrinkage)
\end{itemize}

\todo[inline]{Ask the class, (1) What is a hierarchical model and (2) how do I know when I need a hierarchical model?}

{\bf GOAL: Get to where I draw out a random intercepts model and a random slopes (only) model and a random slopes and intercepts model!}

Go through:
\begin{itemize}
\item random intercepts only
\item random intercepts and slopes
\item examples with different amounts of data for each group
\item exchangeability assumption ... (not sure if this fits here)
\end{itemize}

If I wanted to fit  linear regression to these data and NOT use a hierarchical model, what are my options?

{\bf Be sure to have a plot on board with different amounts of data in different groups.}

{\Large Pooling} % Review pages 256-257 G&H
\begin{itemize}
\item Complete pooling (one line)
\item No pooling (one model for each group
\item Hierarchical models are {\bf partial pooling} -- they exist between these two extremes. 
\end{itemize}

These are useful terms to help you understand what hierarchical models are doing. I use {\bf partial pooling} instead of {\bf shrinkage}. \\
I also do not use {\bf random effects} as a term as it's super unclear across fields and associated with poor understanding of when to use partial pooling in ecology.

\todo[inline]{Ask the class ... what determines HOW MUCH pooling?}

\begin{itemize}
\item $n$ for that group (relative to other groups)
\item variance for that group (relative to other groups)
\item how close it is to overall mean 
\item Model structure to some degree (normal, cauchy etc.)
\end{itemize}

Review: visualizations of partial pooling together \url{https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/}

\subsection{Math of a hierarchical model}
\emph{My notes for this section are mostly on paper (in pencil)}

Start with lmer syntax, then ...
\begin{enumerate}
\item linear regression syntax
\item then move on to hierarchical model syntax
\end{enumerate}

{\bf Be sure to explain hyperparameters} -- (model parameters without group level subscripts (the $\mu$ and $\sigma$ -- overall averages)) and also {\bf hyperpriors}.

\subsection{Let's simulate data from a hierarchical model!}

Get the class to start discussing how to do this; then have them TRY it!

 \todo[inline]{Note to Lizzie: Review code together with me leading... }

\subsection{Pros and cons a hierarchical model}
{\bf This can go BEFORE simulating data ... depending on pace.}

Pros
\begin{itemize}
\item Leverage more data to estimate things you care about
\item Gain overall estimates and make inference at a larger scale
\item Often accommodates a lot of known variation (high $R^2$)
\item You can make inference on unmeasured groups (e.g., you can draw a new species from your distribution)
\end{itemize}

Cons
\begin{itemize}
\item Can be difficult to fit (parameter-rich)
\item Assume you have the data to make inference at a larger scale
\item Exchangeability assumption, especially if you have very uneven sampling (review OSPREE paper visually together)
\end{itemize}
 
 \todo[inline]{Ask the class: Should you fit random effects when you really care or don't care about the effects?}

\subsection{Fixed versus random effects, which is better?}
Remember!

No pooling: $\sigma_{alpha} \rightarrow \inf$\\ % infinity
Complete pooling: $\sigma_{alpha} \rightarrow 0$\\


{\bf Question to Lizzie: Have you discussed exchangeability assumption?!}

\subsection{Crossed versus nested} % We did not get to this, see next class

\subsection{Other stuff}
- Reviewed non-centered parameterization briefly ... 

\subsection{Review the homework assignment!}
 \todo[inline]{{\bf Review the workflow!} Write it up fast with the help of the class ... and then launch into homework assignment...}
\begin{itemize}
\item Datasets ... 
\end{itemize}

\subsection{Some terminology} % included above, but keeping here
Hyperparameters -- model parameters without group level subscripts (the $\mu$ and $\sigma$ -- overall averages)


%%%%%%%%%%%%
%%%%%%%%%%%%
\newpage
\section{Class 5} 

Manipulating posteriors, maybe also forecasting, quantiles etc..

Open with interaction notation and calculate an example with an additive versus subadditive effect (to get them thinking about how these equations work). 

%%%%%%%%%%%%
%%%%%%%%%%%%
\newpage
\section{Class 6} 


Covariance model for phylogeny\\
Latent parameter examples: Do trait model (simplified)\\
Qualitative data (elongated fish example) -- could briefly introduce MXTURE models here, as you could use the shapes as the way to possible define different groups, where each group gets a different body-mass to length relationship. 

\end{document}




\begin{enumerate}
\item
\end{enumerate}


\begin{itemize}
\item
\end{itemize}
